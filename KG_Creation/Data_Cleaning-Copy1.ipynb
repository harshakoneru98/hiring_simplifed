{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1d8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46424ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a4d413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/premrawat/en_model_ner_skills\n",
    "\n",
    "# !pip install pdfminer.six\n",
    "# !pip install docx2txt\n",
    "# !pip install spacy==3.2.4\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "from collections import defaultdict\n",
    "import docx2txt, spacy\n",
    "\n",
    "# input_file = 'Resume.docx'\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    txt = docx2txt.process(docx_path)\n",
    "    if txt:\n",
    "        return txt.replace('\\t', ' ')\n",
    "    return None\n",
    "\n",
    "def preprocessMatchOutput(indexes):\n",
    "    middle_indexes = defaultdict(list)\n",
    "\n",
    "    for k, v in indexes:\n",
    "        middle_indexes[k].append(v)\n",
    "\n",
    "    middle_indexes = {k: max(v) for k, v in middle_indexes.items()}\n",
    "    indexes = list(middle_indexes.items())\n",
    "\n",
    "    middle_indexes = defaultdict(list)\n",
    "    for k, v in indexes:\n",
    "        middle_indexes[v].append(k)\n",
    "\n",
    "    middle_indexes = {min(v):k for k, v in middle_indexes.items()}\n",
    "    indexes = list(middle_indexes.items())\n",
    "    \n",
    "    return indexes\n",
    "\n",
    "nlp = spacy.load(\"en_model_ner_skills\")\n",
    "patterns = [\n",
    "    [{'ENT_TYPE': 'SKILL', 'OP': '+'}]\n",
    "]\n",
    "    \n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"skills\", patterns)\n",
    "\n",
    "def extract_skills(output):\n",
    "    '''\n",
    "    update code to also obtain result as list, so that freq can be obtained for each skill later\n",
    "    '''\n",
    "    doc = nlp(output)\n",
    "\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    indexes = [match[1:] for match in matches]\n",
    "    indexes = preprocessMatchOutput(indexes)\n",
    "\n",
    "    skillset = list()\n",
    "    for (start,end) in indexes:\n",
    "#         print(doc[start:end])\n",
    "        skillset.append(doc[start:end].text)\n",
    "    return skillset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10100598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_int(x):\n",
    "    return ''.join(re.findall(r'\\d+',x))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a2fa167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy sentence tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54cab197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# doc = nlp(\"This is a sentence. This is another sentence.\")\n",
    "# print(doc.has_annotation(\"SENT_START\"))\n",
    "\n",
    "# for sent in doc.sents:\n",
    "#     print(sent.text)\n",
    "nlp_1 = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def H1B_flag(x):\n",
    "    \n",
    "    doc = nlp_1(x)\n",
    "    h1b = 1\n",
    "    for sent in doc.sents:\n",
    "        data = sent.text.upper()\n",
    "        if data.find(\"SPONSOR\")>-1:\n",
    "            if data.find(\"NOT\")>-1:\n",
    "                h1b= 0 \n",
    "        else:\n",
    "            continue\n",
    "    return h1b\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83d60e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(job_data):\n",
    "    Company_name = job_data['Company']\n",
    "    Job_family = job_data['Job_family']\n",
    "    job_location = job_data['job_location']\n",
    "    City_name = job_location.split(\",\")[0]\n",
    "    State = job_location.split(\",\")[1]\n",
    "    Link = job_data['Link']\n",
    "    Title = job_data['Title']\n",
    "    Job_type = \"Full Time\" if job_data['company_overview'].find(\"Full-time\")>-1 else \"Part Time\"\n",
    "    Unique_key = job_data['job_key']\n",
    "    skills = extract_skills(job_data['JD'])\n",
    "    try:\n",
    "        \n",
    "        jd = job_data['JD'].lower()\n",
    "\n",
    "        education_set = set()\n",
    "        if jd.find(\"bachelor's\")>0 or jd.find(\"bachelors’\")>0:\n",
    "            education_set.add(\"Bachelor Degree\")\n",
    "        if jd.find(\"master's\")>0 or jd.find(\"masters’\")>0:\n",
    "            education_set.add(\"Master Degree\")\n",
    "        if jd.find(\"phd\")>0:\n",
    "            education_set.add(\"PhD Degree\")\n",
    "        Education = list(education_set)\n",
    "        if Education==[]:\n",
    "            Education = [\"Bachelor Degree\",\"Master Degree\",\"PhD Degree\"]\n",
    "    except:\n",
    "        Education = [\"Bachelor Degree\",\"Master Degree\",\"PhD Degree\"]\n",
    "    \n",
    "    try:\n",
    "        \n",
    "\n",
    "        Work_max = max([int(re.findall(r'\\d+',w)[0]) for w in re.findall(r\"\\d\\+ years\",jd)])\n",
    "    except:\n",
    "        Work_max = 1\n",
    "    try:\n",
    "\n",
    "        Work_min = min([int(re.findall(r'\\d+',w)[0]) for w in re.findall(r\"\\d\\+ years\",jd)])\n",
    "    except:\n",
    "        Work_min = 1\n",
    "        \n",
    "\n",
    "    overview = job_data['company_overview']\n",
    "    \n",
    "    try:\n",
    "        start_index = re.finditer(\"-time\",overview)\n",
    "        end_index = re.finditer(\"\\+ employees\",overview)\n",
    "\n",
    "        start = [w.end() for w in start_index][0]\n",
    "\n",
    "        end = [w.start() for w in end_index][0]\n",
    "\n",
    "        Employee_Count = overview[start:end]  ##int(get_int(overview[start:end]).replace(\",\",''))\n",
    "    except:\n",
    "        Employee_Count = '10000'\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        end_index = re.finditer(\"\\+ employees\",overview)\n",
    "        start_comp_type = [w.end() for w in end_index][0]\n",
    "\n",
    "\n",
    "        new_string = overview[start_comp_type:]\n",
    "\n",
    "        end_index = re.finditer(\"\\d. school\",new_string)\n",
    "\n",
    "        end = [w.start() for w in end_index][0]\n",
    "\n",
    "        company_type_tmp = new_string[:end]\n",
    "\n",
    "        company_type = re.sub('[^a-zA-Z ]+', '', company_type_tmp).strip()\n",
    "    except:\n",
    "        company_type = 'BFSI'\n",
    "    \n",
    "    \n",
    "\n",
    "    job_dict = {}\n",
    "    job_dict['Company_name'] = Company_name\n",
    "    job_dict['Job_family'] = Job_family\n",
    "    job_dict['job_location'] = job_location\n",
    "    job_dict['City_name'] = City_name\n",
    "    job_dict['State'] = State\n",
    "    job_dict['Link'] = Link\n",
    "    job_dict['Title'] = Title\n",
    "    if Job_type =='':\n",
    "        job_dict['Job_type'] = \"BFSI\"\n",
    "    else:\n",
    "        job_dict['Job_type'] = Job_type\n",
    "    \n",
    "    job_dict['Unique_key'] = Unique_key\n",
    "    job_dict['skills'] = skills\n",
    "    job_dict['Education'] = Education\n",
    "    job_dict['Work_max'] = Work_max\n",
    "    job_dict['Work_min'] = Work_min\n",
    "    job_dict['Employee_Count'] = Employee_Count\n",
    "    job_dict['company_type'] = company_type\n",
    "    job_dict['H1B_Flg'] = H1B_flag(job_data['JD'])\n",
    "    job_dict['Job_Description'] = job_data['JD']\n",
    "    \n",
    "    return job_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96d607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d5545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb7efd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ca9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3267129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"consolidated_jds.json\",'r') as fin:\n",
    "    lines = fin.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f5bb09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_level_list = []\n",
    "# count = 0\n",
    "# #file = open('result1_skill_updated.jsonl', 'w')\n",
    "\n",
    "# for i in lines[:]:\n",
    "    \n",
    "#     job_data = json.loads(i)\n",
    "#     data = H1B_flag(job_data['JD'])\n",
    "#     job_level_list.append(data)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51c08fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_level_list = []\n",
    "count = 0\n",
    "file = open('result1_skill_updated.jsonl', 'w')\n",
    "\n",
    "for i in lines[:]:\n",
    "    \n",
    "    job_data = json.loads(i)\n",
    "    try:\n",
    "        data = get_details(job_data)\n",
    "        job_level_list.append(data)\n",
    "        line = json.dumps(data,ensure_ascii=False) + \"\\n\"\n",
    "        file.write(line) \n",
    "    except:\n",
    "        count+=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
